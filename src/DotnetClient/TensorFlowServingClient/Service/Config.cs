// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/config.proto
#pragma warning disable 1591, 0612, 3021
#region Designer generated code

using pb = global::Google.Protobuf;
using pbc = global::Google.Protobuf.Collections;
using pbr = global::Google.Protobuf.Reflection;
using scg = global::System.Collections.Generic;
namespace Tensorflow {

  /// <summary>Holder for reflection information generated from tensorflow/core/protobuf/config.proto</summary>
  public static partial class ConfigReflection {

    #region Descriptor
    /// <summary>File descriptor for tensorflow/core/protobuf/config.proto</summary>
    public static pbr::FileDescriptor Descriptor {
      get { return descriptor; }
    }
    private static pbr::FileDescriptor descriptor;

    static ConfigReflection() {
      byte[] descriptorData = global::System.Convert.FromBase64String(
          string.Concat(
            "CiV0ZW5zb3JmbG93L2NvcmUvcHJvdG9idWYvY29uZmlnLnByb3RvEgp0ZW5z",
            "b3JmbG93Gip0ZW5zb3JmbG93L2NvcmUvZnJhbWV3b3JrL2Nvc3RfZ3JhcGgu",
            "cHJvdG8aJXRlbnNvcmZsb3cvY29yZS9mcmFtZXdvcmsvZ3JhcGgucHJvdG8a",
            "KnRlbnNvcmZsb3cvY29yZS9mcmFtZXdvcmsvc3RlcF9zdGF0cy5wcm90bxok",
            "dGVuc29yZmxvdy9jb3JlL3Byb3RvYnVmL2RlYnVnLnByb3RvGiZ0ZW5zb3Jm",
            "bG93L2NvcmUvcHJvdG9idWYvY2x1c3Rlci5wcm90bxoudGVuc29yZmxvdy9j",
            "b3JlL3Byb3RvYnVmL3Jld3JpdGVyX2NvbmZpZy5wcm90byKJAgoKR1BVT3B0",
            "aW9ucxInCh9wZXJfcHJvY2Vzc19ncHVfbWVtb3J5X2ZyYWN0aW9uGAEgASgB",
            "EhYKDmFsbG9jYXRvcl90eXBlGAIgASgJEh8KF2RlZmVycmVkX2RlbGV0aW9u",
            "X2J5dGVzGAMgASgDEhQKDGFsbG93X2dyb3d0aBgEIAEoCBIbChN2aXNpYmxl",
            "X2RldmljZV9saXN0GAUgASgJEiIKGnBvbGxpbmdfYWN0aXZlX2RlbGF5X3Vz",
            "ZWNzGAYgASgFEiQKHHBvbGxpbmdfaW5hY3RpdmVfZGVsYXlfbXNlY3MYByAB",
            "KAUSHAoUZm9yY2VfZ3B1X2NvbXBhdGlibGUYCCABKAgihQMKEE9wdGltaXpl",
            "ck9wdGlvbnMSKwojZG9fY29tbW9uX3N1YmV4cHJlc3Npb25fZWxpbWluYXRp",
            "b24YASABKAgSGwoTZG9fY29uc3RhbnRfZm9sZGluZxgCIAEoCBIkChxtYXhf",
            "Zm9sZGVkX2NvbnN0YW50X2luX2J5dGVzGAYgASgDEhwKFGRvX2Z1bmN0aW9u",
            "X2lubGluaW5nGAQgASgIEjUKCW9wdF9sZXZlbBgDIAEoDjIiLnRlbnNvcmZs",
            "b3cuT3B0aW1pemVyT3B0aW9ucy5MZXZlbBJFChBnbG9iYWxfaml0X2xldmVs",
            "GAUgASgOMisudGVuc29yZmxvdy5PcHRpbWl6ZXJPcHRpb25zLkdsb2JhbEpp",
            "dExldmVsIiAKBUxldmVsEgYKAkwxEAASDwoCTDAQ////////////ASJDCg5H",
            "bG9iYWxKaXRMZXZlbBILCgdERUZBVUxUEAASEAoDT0ZGEP///////////wES",
            "CAoET05fMRABEggKBE9OXzIQAiLuAgoMR3JhcGhPcHRpb25zEh4KFmVuYWJs",
            "ZV9yZWN2X3NjaGVkdWxpbmcYAiABKAgSNwoRb3B0aW1pemVyX29wdGlvbnMY",
            "AyABKAsyHC50ZW5zb3JmbG93Lk9wdGltaXplck9wdGlvbnMSGAoQYnVpbGRf",
            "Y29zdF9tb2RlbBgEIAEoAxIeChZidWlsZF9jb3N0X21vZGVsX2FmdGVyGAkg",
            "ASgDEhQKDGluZmVyX3NoYXBlcxgFIAEoCBIaChJwbGFjZV9wcnVuZWRfZ3Jh",
            "cGgYBiABKAgSIAoYZW5hYmxlX2JmbG9hdDE2X3NlbmRyZWN2GAcgASgIEhUK",
            "DXRpbWVsaW5lX3N0ZXAYCCABKAUSMwoPcmV3cml0ZV9vcHRpb25zGAogASgL",
            "MhoudGVuc29yZmxvdy5SZXdyaXRlckNvbmZpZ0oECAEQAlIlc2tpcF9jb21t",
            "b25fc3ViZXhwcmVzc2lvbl9lbGltaW5hdGlvbiJBChVUaHJlYWRQb29sT3B0",
            "aW9uUHJvdG8SEwoLbnVtX3RocmVhZHMYASABKAUSEwoLZ2xvYmFsX25hbWUY",
            "AiABKAkiMgoKUlBDT3B0aW9ucxIkChx1c2VfcnBjX2Zvcl9pbnByb2Nlc3Nf",
            "bWFzdGVyGAEgASgIIv4ECgtDb25maWdQcm90bxI+CgxkZXZpY2VfY291bnQY",
            "ASADKAsyKC50ZW5zb3JmbG93LkNvbmZpZ1Byb3RvLkRldmljZUNvdW50RW50",
            "cnkSJAocaW50cmFfb3BfcGFyYWxsZWxpc21fdGhyZWFkcxgCIAEoBRIkChxp",
            "bnRlcl9vcF9wYXJhbGxlbGlzbV90aHJlYWRzGAUgASgFEh8KF3VzZV9wZXJf",
            "c2Vzc2lvbl90aHJlYWRzGAkgASgIEkcKHHNlc3Npb25faW50ZXJfb3BfdGhy",
            "ZWFkX3Bvb2wYDCADKAsyIS50ZW5zb3JmbG93LlRocmVhZFBvb2xPcHRpb25Q",
            "cm90bxIYChBwbGFjZW1lbnRfcGVyaW9kGAMgASgFEhYKDmRldmljZV9maWx0",
            "ZXJzGAQgAygJEisKC2dwdV9vcHRpb25zGAYgASgLMhYudGVuc29yZmxvdy5H",
            "UFVPcHRpb25zEhwKFGFsbG93X3NvZnRfcGxhY2VtZW50GAcgASgIEhwKFGxv",
            "Z19kZXZpY2VfcGxhY2VtZW50GAggASgIEi8KDWdyYXBoX29wdGlvbnMYCiAB",
            "KAsyGC50ZW5zb3JmbG93LkdyYXBoT3B0aW9ucxIfChdvcGVyYXRpb25fdGlt",
            "ZW91dF9pbl9tcxgLIAEoAxIrCgtycGNfb3B0aW9ucxgNIAEoCzIWLnRlbnNv",
            "cmZsb3cuUlBDT3B0aW9ucxIrCgtjbHVzdGVyX2RlZhgOIAEoCzIWLnRlbnNv",
            "cmZsb3cuQ2x1c3RlckRlZhoyChBEZXZpY2VDb3VudEVudHJ5EgsKA2tleRgB",
            "IAEoCRINCgV2YWx1ZRgCIAEoBToCOAEi0QIKClJ1bk9wdGlvbnMSNgoLdHJh",
            "Y2VfbGV2ZWwYASABKA4yIS50ZW5zb3JmbG93LlJ1bk9wdGlvbnMuVHJhY2VM",
            "ZXZlbBIVCg10aW1lb3V0X2luX21zGAIgASgDEhwKFGludGVyX29wX3RocmVh",
            "ZF9wb29sGAMgASgFEh8KF291dHB1dF9wYXJ0aXRpb25fZ3JhcGhzGAUgASgI",
            "Ei8KDWRlYnVnX29wdGlvbnMYBiABKAsyGC50ZW5zb3JmbG93LkRlYnVnT3B0",
            "aW9ucxIqCiJyZXBvcnRfdGVuc29yX2FsbG9jYXRpb25zX3Vwb25fb29tGAcg",
            "ASgIIlIKClRyYWNlTGV2ZWwSDAoITk9fVFJBQ0UQABISCg5TT0ZUV0FSRV9U",
            "UkFDRRABEhIKDkhBUkRXQVJFX1RSQUNFEAISDgoKRlVMTF9UUkFDRRADSgQI",
            "BBAFIpYBCgtSdW5NZXRhZGF0YRIpCgpzdGVwX3N0YXRzGAEgASgLMhUudGVu",
            "c29yZmxvdy5TdGVwU3RhdHMSLAoKY29zdF9ncmFwaBgCIAEoCzIYLnRlbnNv",
            "cmZsb3cuQ29zdEdyYXBoRGVmEi4KEHBhcnRpdGlvbl9ncmFwaHMYAyADKAsy",
            "FC50ZW5zb3JmbG93LkdyYXBoRGVmQi0KGG9yZy50ZW5zb3JmbG93LmZyYW1l",
            "d29ya0IMQ29uZmlnUHJvdG9zUAH4AQFiBnByb3RvMw=="));
      descriptor = pbr::FileDescriptor.FromGeneratedCode(descriptorData,
          new pbr::FileDescriptor[] { global::Tensorflow.CostGraphReflection.Descriptor, global::Tensorflow.GraphReflection.Descriptor, global::Tensorflow.StepStatsReflection.Descriptor, global::Tensorflow.DebugReflection.Descriptor, global::Tensorflow.ClusterReflection.Descriptor, global::Tensorflow.RewriterConfigReflection.Descriptor, },
          new pbr::GeneratedClrTypeInfo(null, new pbr::GeneratedClrTypeInfo[] {
            new pbr::GeneratedClrTypeInfo(typeof(global::Tensorflow.GPUOptions), global::Tensorflow.GPUOptions.Parser, new[]{ "PerProcessGpuMemoryFraction", "AllocatorType", "DeferredDeletionBytes", "AllowGrowth", "VisibleDeviceList", "PollingActiveDelayUsecs", "PollingInactiveDelayMsecs", "ForceGpuCompatible" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Tensorflow.OptimizerOptions), global::Tensorflow.OptimizerOptions.Parser, new[]{ "DoCommonSubexpressionElimination", "DoConstantFolding", "MaxFoldedConstantInBytes", "DoFunctionInlining", "OptLevel", "GlobalJitLevel" }, null, new[]{ typeof(global::Tensorflow.OptimizerOptions.Types.Level), typeof(global::Tensorflow.OptimizerOptions.Types.GlobalJitLevel) }, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Tensorflow.GraphOptions), global::Tensorflow.GraphOptions.Parser, new[]{ "EnableRecvScheduling", "OptimizerOptions", "BuildCostModel", "BuildCostModelAfter", "InferShapes", "PlacePrunedGraph", "EnableBfloat16Sendrecv", "TimelineStep", "RewriteOptions" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Tensorflow.ThreadPoolOptionProto), global::Tensorflow.ThreadPoolOptionProto.Parser, new[]{ "NumThreads", "GlobalName" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Tensorflow.RPCOptions), global::Tensorflow.RPCOptions.Parser, new[]{ "UseRpcForInprocessMaster" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Tensorflow.ConfigProto), global::Tensorflow.ConfigProto.Parser, new[]{ "DeviceCount", "IntraOpParallelismThreads", "InterOpParallelismThreads", "UsePerSessionThreads", "SessionInterOpThreadPool", "PlacementPeriod", "DeviceFilters", "GpuOptions", "AllowSoftPlacement", "LogDevicePlacement", "GraphOptions", "OperationTimeoutInMs", "RpcOptions", "ClusterDef" }, null, null, new pbr::GeneratedClrTypeInfo[] { null, }),
            new pbr::GeneratedClrTypeInfo(typeof(global::Tensorflow.RunOptions), global::Tensorflow.RunOptions.Parser, new[]{ "TraceLevel", "TimeoutInMs", "InterOpThreadPool", "OutputPartitionGraphs", "DebugOptions", "ReportTensorAllocationsUponOom" }, null, new[]{ typeof(global::Tensorflow.RunOptions.Types.TraceLevel) }, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Tensorflow.RunMetadata), global::Tensorflow.RunMetadata.Parser, new[]{ "StepStats", "CostGraph", "PartitionGraphs" }, null, null, null)
          }));
    }
    #endregion

  }
  #region Messages
  public sealed partial class GPUOptions : pb::IMessage<GPUOptions> {
    private static readonly pb::MessageParser<GPUOptions> _parser = new pb::MessageParser<GPUOptions>(() => new GPUOptions());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<GPUOptions> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Tensorflow.ConfigReflection.Descriptor.MessageTypes[0]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public GPUOptions() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public GPUOptions(GPUOptions other) : this() {
      perProcessGpuMemoryFraction_ = other.perProcessGpuMemoryFraction_;
      allocatorType_ = other.allocatorType_;
      deferredDeletionBytes_ = other.deferredDeletionBytes_;
      allowGrowth_ = other.allowGrowth_;
      visibleDeviceList_ = other.visibleDeviceList_;
      pollingActiveDelayUsecs_ = other.pollingActiveDelayUsecs_;
      pollingInactiveDelayMsecs_ = other.pollingInactiveDelayMsecs_;
      forceGpuCompatible_ = other.forceGpuCompatible_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public GPUOptions Clone() {
      return new GPUOptions(this);
    }

    /// <summary>Field number for the "per_process_gpu_memory_fraction" field.</summary>
    public const int PerProcessGpuMemoryFractionFieldNumber = 1;
    private double perProcessGpuMemoryFraction_;
    /// <summary>
    /// A value between 0 and 1 that indicates what fraction of the
    /// available GPU memory to pre-allocate for each process.  1 means
    /// to pre-allocate all of the GPU memory, 0.5 means the process
    /// allocates ~50% of the available GPU memory.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public double PerProcessGpuMemoryFraction {
      get { return perProcessGpuMemoryFraction_; }
      set {
        perProcessGpuMemoryFraction_ = value;
      }
    }

    /// <summary>Field number for the "allocator_type" field.</summary>
    public const int AllocatorTypeFieldNumber = 2;
    private string allocatorType_ = "";
    /// <summary>
    /// The type of GPU allocation strategy to use.
    ///
    /// Allowed values:
    /// "": The empty string (default) uses a system-chosen default
    ///     which may change over time.
    ///
    /// "BFC": A "Best-fit with coalescing" algorithm, simplified from a
    ///        version of dlmalloc.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string AllocatorType {
      get { return allocatorType_; }
      set {
        allocatorType_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "deferred_deletion_bytes" field.</summary>
    public const int DeferredDeletionBytesFieldNumber = 3;
    private long deferredDeletionBytes_;
    /// <summary>
    /// Delay deletion of up to this many bytes to reduce the number of
    /// interactions with gpu driver code.  If 0, the system chooses
    /// a reasonable default (several MBs).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public long DeferredDeletionBytes {
      get { return deferredDeletionBytes_; }
      set {
        deferredDeletionBytes_ = value;
      }
    }

    /// <summary>Field number for the "allow_growth" field.</summary>
    public const int AllowGrowthFieldNumber = 4;
    private bool allowGrowth_;
    /// <summary>
    /// If true, the allocator does not pre-allocate the entire specified
    /// GPU memory region, instead starting small and growing as needed.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool AllowGrowth {
      get { return allowGrowth_; }
      set {
        allowGrowth_ = value;
      }
    }

    /// <summary>Field number for the "visible_device_list" field.</summary>
    public const int VisibleDeviceListFieldNumber = 5;
    private string visibleDeviceList_ = "";
    /// <summary>
    /// A comma-separated list of GPU ids that determines the 'visible'
    /// to 'virtual' mapping of GPU devices.  For example, if TensorFlow
    /// can see 8 GPU devices in the process, and one wanted to map
    /// visible GPU devices 5 and 3 as "/device:GPU:0", and "/device:GPU:1", then one
    /// would specify this field as "5,3".  This field is similar in
    /// spirit to the CUDA_VISIBLE_DEVICES environment variable, except
    /// it applies to the visible GPU devices in the process.
    ///
    /// NOTE: The GPU driver provides the process with the visible GPUs
    /// in an order which is not guaranteed to have any correlation to
    /// the *physical* GPU id in the machine.  This field is used for
    /// remapping "visible" to "virtual", which means this operates only
    /// after the process starts.  Users are required to use vendor
    /// specific mechanisms (e.g., CUDA_VISIBLE_DEVICES) to control the
    /// physical to visible device mapping prior to invoking TensorFlow.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string VisibleDeviceList {
      get { return visibleDeviceList_; }
      set {
        visibleDeviceList_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "polling_active_delay_usecs" field.</summary>
    public const int PollingActiveDelayUsecsFieldNumber = 6;
    private int pollingActiveDelayUsecs_;
    /// <summary>
    /// In the event polling loop sleep this many microseconds between
    /// PollEvents calls, when the queue is not empty.  If value is not
    /// set or set to 0, gets set to a non-zero default.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int PollingActiveDelayUsecs {
      get { return pollingActiveDelayUsecs_; }
      set {
        pollingActiveDelayUsecs_ = value;
      }
    }

    /// <summary>Field number for the "polling_inactive_delay_msecs" field.</summary>
    public const int PollingInactiveDelayMsecsFieldNumber = 7;
    private int pollingInactiveDelayMsecs_;
    /// <summary>
    /// In the event polling loop sleep this many millisconds between
    /// PollEvents calls, when the queue is empty.  If value is not
    /// set or set to 0, gets set to a non-zero default.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int PollingInactiveDelayMsecs {
      get { return pollingInactiveDelayMsecs_; }
      set {
        pollingInactiveDelayMsecs_ = value;
      }
    }

    /// <summary>Field number for the "force_gpu_compatible" field.</summary>
    public const int ForceGpuCompatibleFieldNumber = 8;
    private bool forceGpuCompatible_;
    /// <summary>
    /// Force all tensors to be gpu_compatible. On a GPU-enabled TensorFlow,
    /// enabling this option forces all CPU tensors to be allocated with Cuda
    /// pinned memory. Normally, TensorFlow will infer which tensors should be
    /// allocated as the pinned memory. But in case where the inference is
    /// incomplete, this option can significantly speed up the cross-device memory
    /// copy performance as long as it fits the memory.
    /// Note that this option is not something that should be
    /// enabled by default for unknown or very large models, since all Cuda pinned
    /// memory is unpageable, having too much pinned memory might negatively impact
    /// the overall host system performance.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool ForceGpuCompatible {
      get { return forceGpuCompatible_; }
      set {
        forceGpuCompatible_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as GPUOptions);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(GPUOptions other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (PerProcessGpuMemoryFraction != other.PerProcessGpuMemoryFraction) return false;
      if (AllocatorType != other.AllocatorType) return false;
      if (DeferredDeletionBytes != other.DeferredDeletionBytes) return false;
      if (AllowGrowth != other.AllowGrowth) return false;
      if (VisibleDeviceList != other.VisibleDeviceList) return false;
      if (PollingActiveDelayUsecs != other.PollingActiveDelayUsecs) return false;
      if (PollingInactiveDelayMsecs != other.PollingInactiveDelayMsecs) return false;
      if (ForceGpuCompatible != other.ForceGpuCompatible) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (PerProcessGpuMemoryFraction != 0D) hash ^= PerProcessGpuMemoryFraction.GetHashCode();
      if (AllocatorType.Length != 0) hash ^= AllocatorType.GetHashCode();
      if (DeferredDeletionBytes != 0L) hash ^= DeferredDeletionBytes.GetHashCode();
      if (AllowGrowth != false) hash ^= AllowGrowth.GetHashCode();
      if (VisibleDeviceList.Length != 0) hash ^= VisibleDeviceList.GetHashCode();
      if (PollingActiveDelayUsecs != 0) hash ^= PollingActiveDelayUsecs.GetHashCode();
      if (PollingInactiveDelayMsecs != 0) hash ^= PollingInactiveDelayMsecs.GetHashCode();
      if (ForceGpuCompatible != false) hash ^= ForceGpuCompatible.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (PerProcessGpuMemoryFraction != 0D) {
        output.WriteRawTag(9);
        output.WriteDouble(PerProcessGpuMemoryFraction);
      }
      if (AllocatorType.Length != 0) {
        output.WriteRawTag(18);
        output.WriteString(AllocatorType);
      }
      if (DeferredDeletionBytes != 0L) {
        output.WriteRawTag(24);
        output.WriteInt64(DeferredDeletionBytes);
      }
      if (AllowGrowth != false) {
        output.WriteRawTag(32);
        output.WriteBool(AllowGrowth);
      }
      if (VisibleDeviceList.Length != 0) {
        output.WriteRawTag(42);
        output.WriteString(VisibleDeviceList);
      }
      if (PollingActiveDelayUsecs != 0) {
        output.WriteRawTag(48);
        output.WriteInt32(PollingActiveDelayUsecs);
      }
      if (PollingInactiveDelayMsecs != 0) {
        output.WriteRawTag(56);
        output.WriteInt32(PollingInactiveDelayMsecs);
      }
      if (ForceGpuCompatible != false) {
        output.WriteRawTag(64);
        output.WriteBool(ForceGpuCompatible);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (PerProcessGpuMemoryFraction != 0D) {
        size += 1 + 8;
      }
      if (AllocatorType.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(AllocatorType);
      }
      if (DeferredDeletionBytes != 0L) {
        size += 1 + pb::CodedOutputStream.ComputeInt64Size(DeferredDeletionBytes);
      }
      if (AllowGrowth != false) {
        size += 1 + 1;
      }
      if (VisibleDeviceList.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(VisibleDeviceList);
      }
      if (PollingActiveDelayUsecs != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(PollingActiveDelayUsecs);
      }
      if (PollingInactiveDelayMsecs != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(PollingInactiveDelayMsecs);
      }
      if (ForceGpuCompatible != false) {
        size += 1 + 1;
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(GPUOptions other) {
      if (other == null) {
        return;
      }
      if (other.PerProcessGpuMemoryFraction != 0D) {
        PerProcessGpuMemoryFraction = other.PerProcessGpuMemoryFraction;
      }
      if (other.AllocatorType.Length != 0) {
        AllocatorType = other.AllocatorType;
      }
      if (other.DeferredDeletionBytes != 0L) {
        DeferredDeletionBytes = other.DeferredDeletionBytes;
      }
      if (other.AllowGrowth != false) {
        AllowGrowth = other.AllowGrowth;
      }
      if (other.VisibleDeviceList.Length != 0) {
        VisibleDeviceList = other.VisibleDeviceList;
      }
      if (other.PollingActiveDelayUsecs != 0) {
        PollingActiveDelayUsecs = other.PollingActiveDelayUsecs;
      }
      if (other.PollingInactiveDelayMsecs != 0) {
        PollingInactiveDelayMsecs = other.PollingInactiveDelayMsecs;
      }
      if (other.ForceGpuCompatible != false) {
        ForceGpuCompatible = other.ForceGpuCompatible;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 9: {
            PerProcessGpuMemoryFraction = input.ReadDouble();
            break;
          }
          case 18: {
            AllocatorType = input.ReadString();
            break;
          }
          case 24: {
            DeferredDeletionBytes = input.ReadInt64();
            break;
          }
          case 32: {
            AllowGrowth = input.ReadBool();
            break;
          }
          case 42: {
            VisibleDeviceList = input.ReadString();
            break;
          }
          case 48: {
            PollingActiveDelayUsecs = input.ReadInt32();
            break;
          }
          case 56: {
            PollingInactiveDelayMsecs = input.ReadInt32();
            break;
          }
          case 64: {
            ForceGpuCompatible = input.ReadBool();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// Options passed to the graph optimizer
  /// </summary>
  public sealed partial class OptimizerOptions : pb::IMessage<OptimizerOptions> {
    private static readonly pb::MessageParser<OptimizerOptions> _parser = new pb::MessageParser<OptimizerOptions>(() => new OptimizerOptions());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<OptimizerOptions> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Tensorflow.ConfigReflection.Descriptor.MessageTypes[1]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public OptimizerOptions() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public OptimizerOptions(OptimizerOptions other) : this() {
      doCommonSubexpressionElimination_ = other.doCommonSubexpressionElimination_;
      doConstantFolding_ = other.doConstantFolding_;
      maxFoldedConstantInBytes_ = other.maxFoldedConstantInBytes_;
      doFunctionInlining_ = other.doFunctionInlining_;
      optLevel_ = other.optLevel_;
      globalJitLevel_ = other.globalJitLevel_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public OptimizerOptions Clone() {
      return new OptimizerOptions(this);
    }

    /// <summary>Field number for the "do_common_subexpression_elimination" field.</summary>
    public const int DoCommonSubexpressionEliminationFieldNumber = 1;
    private bool doCommonSubexpressionElimination_;
    /// <summary>
    /// If true, optimize the graph using common subexpression elimination.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool DoCommonSubexpressionElimination {
      get { return doCommonSubexpressionElimination_; }
      set {
        doCommonSubexpressionElimination_ = value;
      }
    }

    /// <summary>Field number for the "do_constant_folding" field.</summary>
    public const int DoConstantFoldingFieldNumber = 2;
    private bool doConstantFolding_;
    /// <summary>
    /// If true, perform constant folding optimization on the graph.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool DoConstantFolding {
      get { return doConstantFolding_; }
      set {
        doConstantFolding_ = value;
      }
    }

    /// <summary>Field number for the "max_folded_constant_in_bytes" field.</summary>
    public const int MaxFoldedConstantInBytesFieldNumber = 6;
    private long maxFoldedConstantInBytes_;
    /// <summary>
    /// Constant folding optimization replaces tensors whose values can be
    /// predetermined, with constant nodes. To avoid inserting too large constants,
    /// the size of each constant created can be limited. If this value is zero, a
    /// default limit of 10 MiB will be applied. If constant folding optimization
    /// is disabled, this value is ignored.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public long MaxFoldedConstantInBytes {
      get { return maxFoldedConstantInBytes_; }
      set {
        maxFoldedConstantInBytes_ = value;
      }
    }

    /// <summary>Field number for the "do_function_inlining" field.</summary>
    public const int DoFunctionInliningFieldNumber = 4;
    private bool doFunctionInlining_;
    /// <summary>
    /// If true, perform function inlining on the graph.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool DoFunctionInlining {
      get { return doFunctionInlining_; }
      set {
        doFunctionInlining_ = value;
      }
    }

    /// <summary>Field number for the "opt_level" field.</summary>
    public const int OptLevelFieldNumber = 3;
    private global::Tensorflow.OptimizerOptions.Types.Level optLevel_ = 0;
    /// <summary>
    /// Overall optimization level. The actual optimizations applied will be the
    /// logical OR of the flags that this level implies and any flags already set.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Tensorflow.OptimizerOptions.Types.Level OptLevel {
      get { return optLevel_; }
      set {
        optLevel_ = value;
      }
    }

    /// <summary>Field number for the "global_jit_level" field.</summary>
    public const int GlobalJitLevelFieldNumber = 5;
    private global::Tensorflow.OptimizerOptions.Types.GlobalJitLevel globalJitLevel_ = 0;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Tensorflow.OptimizerOptions.Types.GlobalJitLevel GlobalJitLevel {
      get { return globalJitLevel_; }
      set {
        globalJitLevel_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as OptimizerOptions);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(OptimizerOptions other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (DoCommonSubexpressionElimination != other.DoCommonSubexpressionElimination) return false;
      if (DoConstantFolding != other.DoConstantFolding) return false;
      if (MaxFoldedConstantInBytes != other.MaxFoldedConstantInBytes) return false;
      if (DoFunctionInlining != other.DoFunctionInlining) return false;
      if (OptLevel != other.OptLevel) return false;
      if (GlobalJitLevel != other.GlobalJitLevel) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (DoCommonSubexpressionElimination != false) hash ^= DoCommonSubexpressionElimination.GetHashCode();
      if (DoConstantFolding != false) hash ^= DoConstantFolding.GetHashCode();
      if (MaxFoldedConstantInBytes != 0L) hash ^= MaxFoldedConstantInBytes.GetHashCode();
      if (DoFunctionInlining != false) hash ^= DoFunctionInlining.GetHashCode();
      if (OptLevel != 0) hash ^= OptLevel.GetHashCode();
      if (GlobalJitLevel != 0) hash ^= GlobalJitLevel.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (DoCommonSubexpressionElimination != false) {
        output.WriteRawTag(8);
        output.WriteBool(DoCommonSubexpressionElimination);
      }
      if (DoConstantFolding != false) {
        output.WriteRawTag(16);
        output.WriteBool(DoConstantFolding);
      }
      if (OptLevel != 0) {
        output.WriteRawTag(24);
        output.WriteEnum((int) OptLevel);
      }
      if (DoFunctionInlining != false) {
        output.WriteRawTag(32);
        output.WriteBool(DoFunctionInlining);
      }
      if (GlobalJitLevel != 0) {
        output.WriteRawTag(40);
        output.WriteEnum((int) GlobalJitLevel);
      }
      if (MaxFoldedConstantInBytes != 0L) {
        output.WriteRawTag(48);
        output.WriteInt64(MaxFoldedConstantInBytes);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (DoCommonSubexpressionElimination != false) {
        size += 1 + 1;
      }
      if (DoConstantFolding != false) {
        size += 1 + 1;
      }
      if (MaxFoldedConstantInBytes != 0L) {
        size += 1 + pb::CodedOutputStream.ComputeInt64Size(MaxFoldedConstantInBytes);
      }
      if (DoFunctionInlining != false) {
        size += 1 + 1;
      }
      if (OptLevel != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) OptLevel);
      }
      if (GlobalJitLevel != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) GlobalJitLevel);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(OptimizerOptions other) {
      if (other == null) {
        return;
      }
      if (other.DoCommonSubexpressionElimination != false) {
        DoCommonSubexpressionElimination = other.DoCommonSubexpressionElimination;
      }
      if (other.DoConstantFolding != false) {
        DoConstantFolding = other.DoConstantFolding;
      }
      if (other.MaxFoldedConstantInBytes != 0L) {
        MaxFoldedConstantInBytes = other.MaxFoldedConstantInBytes;
      }
      if (other.DoFunctionInlining != false) {
        DoFunctionInlining = other.DoFunctionInlining;
      }
      if (other.OptLevel != 0) {
        OptLevel = other.OptLevel;
      }
      if (other.GlobalJitLevel != 0) {
        GlobalJitLevel = other.GlobalJitLevel;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 8: {
            DoCommonSubexpressionElimination = input.ReadBool();
            break;
          }
          case 16: {
            DoConstantFolding = input.ReadBool();
            break;
          }
          case 24: {
            optLevel_ = (global::Tensorflow.OptimizerOptions.Types.Level) input.ReadEnum();
            break;
          }
          case 32: {
            DoFunctionInlining = input.ReadBool();
            break;
          }
          case 40: {
            globalJitLevel_ = (global::Tensorflow.OptimizerOptions.Types.GlobalJitLevel) input.ReadEnum();
            break;
          }
          case 48: {
            MaxFoldedConstantInBytes = input.ReadInt64();
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the OptimizerOptions message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      /// Optimization level
      /// </summary>
      public enum Level {
        /// <summary>
        /// L1 is the default level.
        /// Optimization performed at L1 :
        /// 1. Common subexpression elimination
        /// 2. Constant folding
        /// </summary>
        [pbr::OriginalName("L1")] L1 = 0,
        /// <summary>
        /// No optimizations
        /// </summary>
        [pbr::OriginalName("L0")] L0 = -1,
      }

      /// <summary>
      /// Control the use of the compiler/jit.  Experimental.
      /// </summary>
      public enum GlobalJitLevel {
        /// <summary>
        /// Default setting ("off" now, but later expected to be "on")
        /// </summary>
        [pbr::OriginalName("DEFAULT")] Default = 0,
        [pbr::OriginalName("OFF")] Off = -1,
        /// <summary>
        /// The following settings turn on compilation, with higher values being
        /// more aggressive.  Higher values may reduce opportunities for parallelism
        /// and may use more memory.  (At present, there is no distinction, but this
        /// is expected to change.)
        /// </summary>
        [pbr::OriginalName("ON_1")] On1 = 1,
        [pbr::OriginalName("ON_2")] On2 = 2,
      }

    }
    #endregion

  }

  public sealed partial class GraphOptions : pb::IMessage<GraphOptions> {
    private static readonly pb::MessageParser<GraphOptions> _parser = new pb::MessageParser<GraphOptions>(() => new GraphOptions());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<GraphOptions> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Tensorflow.ConfigReflection.Descriptor.MessageTypes[2]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public GraphOptions() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public GraphOptions(GraphOptions other) : this() {
      enableRecvScheduling_ = other.enableRecvScheduling_;
      OptimizerOptions = other.optimizerOptions_ != null ? other.OptimizerOptions.Clone() : null;
      buildCostModel_ = other.buildCostModel_;
      buildCostModelAfter_ = other.buildCostModelAfter_;
      inferShapes_ = other.inferShapes_;
      placePrunedGraph_ = other.placePrunedGraph_;
      enableBfloat16Sendrecv_ = other.enableBfloat16Sendrecv_;
      timelineStep_ = other.timelineStep_;
      RewriteOptions = other.rewriteOptions_ != null ? other.RewriteOptions.Clone() : null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public GraphOptions Clone() {
      return new GraphOptions(this);
    }

    /// <summary>Field number for the "enable_recv_scheduling" field.</summary>
    public const int EnableRecvSchedulingFieldNumber = 2;
    private bool enableRecvScheduling_;
    /// <summary>
    /// If true, use control flow to schedule the activation of Recv nodes.
    /// (Currently ignored.)
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool EnableRecvScheduling {
      get { return enableRecvScheduling_; }
      set {
        enableRecvScheduling_ = value;
      }
    }

    /// <summary>Field number for the "optimizer_options" field.</summary>
    public const int OptimizerOptionsFieldNumber = 3;
    private global::Tensorflow.OptimizerOptions optimizerOptions_;
    /// <summary>
    /// Options controlling how graph is optimized.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Tensorflow.OptimizerOptions OptimizerOptions {
      get { return optimizerOptions_; }
      set {
        optimizerOptions_ = value;
      }
    }

    /// <summary>Field number for the "build_cost_model" field.</summary>
    public const int BuildCostModelFieldNumber = 4;
    private long buildCostModel_;
    /// <summary>
    /// The number of steps to run before returning a cost model detailing
    /// the memory usage and performance of each node of the graph. 0 means
    /// no cost model.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public long BuildCostModel {
      get { return buildCostModel_; }
      set {
        buildCostModel_ = value;
      }
    }

    /// <summary>Field number for the "build_cost_model_after" field.</summary>
    public const int BuildCostModelAfterFieldNumber = 9;
    private long buildCostModelAfter_;
    /// <summary>
    /// The number of steps to skip before collecting statistics for the
    /// cost model.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public long BuildCostModelAfter {
      get { return buildCostModelAfter_; }
      set {
        buildCostModelAfter_ = value;
      }
    }

    /// <summary>Field number for the "infer_shapes" field.</summary>
    public const int InferShapesFieldNumber = 5;
    private bool inferShapes_;
    /// <summary>
    /// Annotate each Node with Op output shape data, to the extent it can
    /// be statically inferred.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool InferShapes {
      get { return inferShapes_; }
      set {
        inferShapes_ = value;
      }
    }

    /// <summary>Field number for the "place_pruned_graph" field.</summary>
    public const int PlacePrunedGraphFieldNumber = 6;
    private bool placePrunedGraph_;
    /// <summary>
    /// Only place the subgraphs that are run, rather than the entire graph.
    ///
    /// This is useful for interactive graph building, where one might
    /// produce graphs that cannot be placed during the debugging
    /// process.  In particular, it allows the client to continue work in
    /// a session after adding a node to a graph whose placement
    /// constraints are unsatisfiable.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool PlacePrunedGraph {
      get { return placePrunedGraph_; }
      set {
        placePrunedGraph_ = value;
      }
    }

    /// <summary>Field number for the "enable_bfloat16_sendrecv" field.</summary>
    public const int EnableBfloat16SendrecvFieldNumber = 7;
    private bool enableBfloat16Sendrecv_;
    /// <summary>
    /// If true, transfer float values between processes as bfloat16.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool EnableBfloat16Sendrecv {
      get { return enableBfloat16Sendrecv_; }
      set {
        enableBfloat16Sendrecv_ = value;
      }
    }

    /// <summary>Field number for the "timeline_step" field.</summary>
    public const int TimelineStepFieldNumber = 8;
    private int timelineStep_;
    /// <summary>
    /// If > 0, record a timeline every this many steps.
    /// EXPERIMENTAL: This currently has no effect in MasterSession.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int TimelineStep {
      get { return timelineStep_; }
      set {
        timelineStep_ = value;
      }
    }

    /// <summary>Field number for the "rewrite_options" field.</summary>
    public const int RewriteOptionsFieldNumber = 10;
    private global::Tensorflow.RewriterConfig rewriteOptions_;
    /// <summary>
    /// Options that control the type and amount of graph rewriting.
    /// Not currently configurable via the public Python API (i.e. there is no API
    /// stability guarantee if you import RewriterConfig explicitly).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Tensorflow.RewriterConfig RewriteOptions {
      get { return rewriteOptions_; }
      set {
        rewriteOptions_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as GraphOptions);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(GraphOptions other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (EnableRecvScheduling != other.EnableRecvScheduling) return false;
      if (!object.Equals(OptimizerOptions, other.OptimizerOptions)) return false;
      if (BuildCostModel != other.BuildCostModel) return false;
      if (BuildCostModelAfter != other.BuildCostModelAfter) return false;
      if (InferShapes != other.InferShapes) return false;
      if (PlacePrunedGraph != other.PlacePrunedGraph) return false;
      if (EnableBfloat16Sendrecv != other.EnableBfloat16Sendrecv) return false;
      if (TimelineStep != other.TimelineStep) return false;
      if (!object.Equals(RewriteOptions, other.RewriteOptions)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (EnableRecvScheduling != false) hash ^= EnableRecvScheduling.GetHashCode();
      if (optimizerOptions_ != null) hash ^= OptimizerOptions.GetHashCode();
      if (BuildCostModel != 0L) hash ^= BuildCostModel.GetHashCode();
      if (BuildCostModelAfter != 0L) hash ^= BuildCostModelAfter.GetHashCode();
      if (InferShapes != false) hash ^= InferShapes.GetHashCode();
      if (PlacePrunedGraph != false) hash ^= PlacePrunedGraph.GetHashCode();
      if (EnableBfloat16Sendrecv != false) hash ^= EnableBfloat16Sendrecv.GetHashCode();
      if (TimelineStep != 0) hash ^= TimelineStep.GetHashCode();
      if (rewriteOptions_ != null) hash ^= RewriteOptions.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (EnableRecvScheduling != false) {
        output.WriteRawTag(16);
        output.WriteBool(EnableRecvScheduling);
      }
      if (optimizerOptions_ != null) {
        output.WriteRawTag(26);
        output.WriteMessage(OptimizerOptions);
      }
      if (BuildCostModel != 0L) {
        output.WriteRawTag(32);
        output.WriteInt64(BuildCostModel);
      }
      if (InferShapes != false) {
        output.WriteRawTag(40);
        output.WriteBool(InferShapes);
      }
      if (PlacePrunedGraph != false) {
        output.WriteRawTag(48);
        output.WriteBool(PlacePrunedGraph);
      }
      if (EnableBfloat16Sendrecv != false) {
        output.WriteRawTag(56);
        output.WriteBool(EnableBfloat16Sendrecv);
      }
      if (TimelineStep != 0) {
        output.WriteRawTag(64);
        output.WriteInt32(TimelineStep);
      }
      if (BuildCostModelAfter != 0L) {
        output.WriteRawTag(72);
        output.WriteInt64(BuildCostModelAfter);
      }
      if (rewriteOptions_ != null) {
        output.WriteRawTag(82);
        output.WriteMessage(RewriteOptions);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (EnableRecvScheduling != false) {
        size += 1 + 1;
      }
      if (optimizerOptions_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(OptimizerOptions);
      }
      if (BuildCostModel != 0L) {
        size += 1 + pb::CodedOutputStream.ComputeInt64Size(BuildCostModel);
      }
      if (BuildCostModelAfter != 0L) {
        size += 1 + pb::CodedOutputStream.ComputeInt64Size(BuildCostModelAfter);
      }
      if (InferShapes != false) {
        size += 1 + 1;
      }
      if (PlacePrunedGraph != false) {
        size += 1 + 1;
      }
      if (EnableBfloat16Sendrecv != false) {
        size += 1 + 1;
      }
      if (TimelineStep != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(TimelineStep);
      }
      if (rewriteOptions_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(RewriteOptions);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(GraphOptions other) {
      if (other == null) {
        return;
      }
      if (other.EnableRecvScheduling != false) {
        EnableRecvScheduling = other.EnableRecvScheduling;
      }
      if (other.optimizerOptions_ != null) {
        if (optimizerOptions_ == null) {
          optimizerOptions_ = new global::Tensorflow.OptimizerOptions();
        }
        OptimizerOptions.MergeFrom(other.OptimizerOptions);
      }
      if (other.BuildCostModel != 0L) {
        BuildCostModel = other.BuildCostModel;
      }
      if (other.BuildCostModelAfter != 0L) {
        BuildCostModelAfter = other.BuildCostModelAfter;
      }
      if (other.InferShapes != false) {
        InferShapes = other.InferShapes;
      }
      if (other.PlacePrunedGraph != false) {
        PlacePrunedGraph = other.PlacePrunedGraph;
      }
      if (other.EnableBfloat16Sendrecv != false) {
        EnableBfloat16Sendrecv = other.EnableBfloat16Sendrecv;
      }
      if (other.TimelineStep != 0) {
        TimelineStep = other.TimelineStep;
      }
      if (other.rewriteOptions_ != null) {
        if (rewriteOptions_ == null) {
          rewriteOptions_ = new global::Tensorflow.RewriterConfig();
        }
        RewriteOptions.MergeFrom(other.RewriteOptions);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 16: {
            EnableRecvScheduling = input.ReadBool();
            break;
          }
          case 26: {
            if (optimizerOptions_ == null) {
              optimizerOptions_ = new global::Tensorflow.OptimizerOptions();
            }
            input.ReadMessage(optimizerOptions_);
            break;
          }
          case 32: {
            BuildCostModel = input.ReadInt64();
            break;
          }
          case 40: {
            InferShapes = input.ReadBool();
            break;
          }
          case 48: {
            PlacePrunedGraph = input.ReadBool();
            break;
          }
          case 56: {
            EnableBfloat16Sendrecv = input.ReadBool();
            break;
          }
          case 64: {
            TimelineStep = input.ReadInt32();
            break;
          }
          case 72: {
            BuildCostModelAfter = input.ReadInt64();
            break;
          }
          case 82: {
            if (rewriteOptions_ == null) {
              rewriteOptions_ = new global::Tensorflow.RewriterConfig();
            }
            input.ReadMessage(rewriteOptions_);
            break;
          }
        }
      }
    }

  }

  public sealed partial class ThreadPoolOptionProto : pb::IMessage<ThreadPoolOptionProto> {
    private static readonly pb::MessageParser<ThreadPoolOptionProto> _parser = new pb::MessageParser<ThreadPoolOptionProto>(() => new ThreadPoolOptionProto());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<ThreadPoolOptionProto> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Tensorflow.ConfigReflection.Descriptor.MessageTypes[3]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ThreadPoolOptionProto() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ThreadPoolOptionProto(ThreadPoolOptionProto other) : this() {
      numThreads_ = other.numThreads_;
      globalName_ = other.globalName_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ThreadPoolOptionProto Clone() {
      return new ThreadPoolOptionProto(this);
    }

    /// <summary>Field number for the "num_threads" field.</summary>
    public const int NumThreadsFieldNumber = 1;
    private int numThreads_;
    /// <summary>
    /// The number of threads in the pool.
    ///
    /// 0 means the system picks a value based on where this option proto is used
    /// (see the declaration of the specific field for more info).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int NumThreads {
      get { return numThreads_; }
      set {
        numThreads_ = value;
      }
    }

    /// <summary>Field number for the "global_name" field.</summary>
    public const int GlobalNameFieldNumber = 2;
    private string globalName_ = "";
    /// <summary>
    /// The global name of the threadpool.
    ///
    /// If empty, then the threadpool is made and used according to the scope it's
    /// in - e.g., for a session threadpool, it is used by that session only.
    ///
    /// If non-empty, then:
    /// - a global threadpool associated with this name is looked
    ///   up or created. This allows, for example, sharing one threadpool across
    ///   many sessions (e.g., like the default behavior, if
    ///   inter_op_parallelism_threads is not configured), but still partitioning
    ///   into a large and small pool.
    /// - if the threadpool for this global_name already exists, then it is an
    ///   error if the existing pool was created using a different num_threads
    ///   value as is specified on this call.
    /// - threadpools created this way are never garbage collected.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string GlobalName {
      get { return globalName_; }
      set {
        globalName_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as ThreadPoolOptionProto);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(ThreadPoolOptionProto other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (NumThreads != other.NumThreads) return false;
      if (GlobalName != other.GlobalName) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (NumThreads != 0) hash ^= NumThreads.GetHashCode();
      if (GlobalName.Length != 0) hash ^= GlobalName.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (NumThreads != 0) {
        output.WriteRawTag(8);
        output.WriteInt32(NumThreads);
      }
      if (GlobalName.Length != 0) {
        output.WriteRawTag(18);
        output.WriteString(GlobalName);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (NumThreads != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(NumThreads);
      }
      if (GlobalName.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(GlobalName);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(ThreadPoolOptionProto other) {
      if (other == null) {
        return;
      }
      if (other.NumThreads != 0) {
        NumThreads = other.NumThreads;
      }
      if (other.GlobalName.Length != 0) {
        GlobalName = other.GlobalName;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 8: {
            NumThreads = input.ReadInt32();
            break;
          }
          case 18: {
            GlobalName = input.ReadString();
            break;
          }
        }
      }
    }

  }

  public sealed partial class RPCOptions : pb::IMessage<RPCOptions> {
    private static readonly pb::MessageParser<RPCOptions> _parser = new pb::MessageParser<RPCOptions>(() => new RPCOptions());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<RPCOptions> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Tensorflow.ConfigReflection.Descriptor.MessageTypes[4]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RPCOptions() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RPCOptions(RPCOptions other) : this() {
      useRpcForInprocessMaster_ = other.useRpcForInprocessMaster_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RPCOptions Clone() {
      return new RPCOptions(this);
    }

    /// <summary>Field number for the "use_rpc_for_inprocess_master" field.</summary>
    public const int UseRpcForInprocessMasterFieldNumber = 1;
    private bool useRpcForInprocessMaster_;
    /// <summary>
    /// If true, always use RPC to contact the session target.
    ///
    /// If false (the default option), TensorFlow may use an optimized
    /// transport for client-master communication that avoids the RPC
    /// stack. This option is primarily for used testing the RPC stack.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool UseRpcForInprocessMaster {
      get { return useRpcForInprocessMaster_; }
      set {
        useRpcForInprocessMaster_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as RPCOptions);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(RPCOptions other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (UseRpcForInprocessMaster != other.UseRpcForInprocessMaster) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (UseRpcForInprocessMaster != false) hash ^= UseRpcForInprocessMaster.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (UseRpcForInprocessMaster != false) {
        output.WriteRawTag(8);
        output.WriteBool(UseRpcForInprocessMaster);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (UseRpcForInprocessMaster != false) {
        size += 1 + 1;
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(RPCOptions other) {
      if (other == null) {
        return;
      }
      if (other.UseRpcForInprocessMaster != false) {
        UseRpcForInprocessMaster = other.UseRpcForInprocessMaster;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 8: {
            UseRpcForInprocessMaster = input.ReadBool();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// Session configuration parameters.
  /// The system picks appropriate values for fields that are not set.
  /// </summary>
  public sealed partial class ConfigProto : pb::IMessage<ConfigProto> {
    private static readonly pb::MessageParser<ConfigProto> _parser = new pb::MessageParser<ConfigProto>(() => new ConfigProto());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<ConfigProto> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Tensorflow.ConfigReflection.Descriptor.MessageTypes[5]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConfigProto() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConfigProto(ConfigProto other) : this() {
      deviceCount_ = other.deviceCount_.Clone();
      intraOpParallelismThreads_ = other.intraOpParallelismThreads_;
      interOpParallelismThreads_ = other.interOpParallelismThreads_;
      usePerSessionThreads_ = other.usePerSessionThreads_;
      sessionInterOpThreadPool_ = other.sessionInterOpThreadPool_.Clone();
      placementPeriod_ = other.placementPeriod_;
      deviceFilters_ = other.deviceFilters_.Clone();
      GpuOptions = other.gpuOptions_ != null ? other.GpuOptions.Clone() : null;
      allowSoftPlacement_ = other.allowSoftPlacement_;
      logDevicePlacement_ = other.logDevicePlacement_;
      GraphOptions = other.graphOptions_ != null ? other.GraphOptions.Clone() : null;
      operationTimeoutInMs_ = other.operationTimeoutInMs_;
      RpcOptions = other.rpcOptions_ != null ? other.RpcOptions.Clone() : null;
      ClusterDef = other.clusterDef_ != null ? other.ClusterDef.Clone() : null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConfigProto Clone() {
      return new ConfigProto(this);
    }

    /// <summary>Field number for the "device_count" field.</summary>
    public const int DeviceCountFieldNumber = 1;
    private static readonly pbc::MapField<string, int>.Codec _map_deviceCount_codec
        = new pbc::MapField<string, int>.Codec(pb::FieldCodec.ForString(10), pb::FieldCodec.ForInt32(16), 10);
    private readonly pbc::MapField<string, int> deviceCount_ = new pbc::MapField<string, int>();
    /// <summary>
    /// Map from device type name (e.g., "CPU" or "GPU" ) to maximum
    /// number of devices of that type to use.  If a particular device
    /// type is not found in the map, the system picks an appropriate
    /// number.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::MapField<string, int> DeviceCount {
      get { return deviceCount_; }
    }

    /// <summary>Field number for the "intra_op_parallelism_threads" field.</summary>
    public const int IntraOpParallelismThreadsFieldNumber = 2;
    private int intraOpParallelismThreads_;
    /// <summary>
    /// The execution of an individual op (for some op types) can be
    /// parallelized on a pool of intra_op_parallelism_threads.
    /// 0 means the system picks an appropriate number.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int IntraOpParallelismThreads {
      get { return intraOpParallelismThreads_; }
      set {
        intraOpParallelismThreads_ = value;
      }
    }

    /// <summary>Field number for the "inter_op_parallelism_threads" field.</summary>
    public const int InterOpParallelismThreadsFieldNumber = 5;
    private int interOpParallelismThreads_;
    /// <summary>
    /// Nodes that perform blocking operations are enqueued on a pool of
    /// inter_op_parallelism_threads available in each process.
    ///
    /// 0 means the system picks an appropriate number.
    ///
    /// Note that the first Session created in the process sets the
    /// number of threads for all future sessions unless use_per_session_threads is
    /// true or session_inter_op_thread_pool is configured.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int InterOpParallelismThreads {
      get { return interOpParallelismThreads_; }
      set {
        interOpParallelismThreads_ = value;
      }
    }

    /// <summary>Field number for the "use_per_session_threads" field.</summary>
    public const int UsePerSessionThreadsFieldNumber = 9;
    private bool usePerSessionThreads_;
    /// <summary>
    /// If true, use a new set of threads for this session rather than the global
    /// pool of threads. Only supported by direct sessions.
    ///
    /// If false, use the global threads created by the first session, or the
    /// per-session thread pools configured by session_inter_op_thread_pool.
    ///
    /// This option is deprecated. The same effect can be achieved by setting
    /// session_inter_op_thread_pool to have one element, whose num_threads equals
    /// inter_op_parallelism_threads.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool UsePerSessionThreads {
      get { return usePerSessionThreads_; }
      set {
        usePerSessionThreads_ = value;
      }
    }

    /// <summary>Field number for the "session_inter_op_thread_pool" field.</summary>
    public const int SessionInterOpThreadPoolFieldNumber = 12;
    private static readonly pb::FieldCodec<global::Tensorflow.ThreadPoolOptionProto> _repeated_sessionInterOpThreadPool_codec
        = pb::FieldCodec.ForMessage(98, global::Tensorflow.ThreadPoolOptionProto.Parser);
    private readonly pbc::RepeatedField<global::Tensorflow.ThreadPoolOptionProto> sessionInterOpThreadPool_ = new pbc::RepeatedField<global::Tensorflow.ThreadPoolOptionProto>();
    /// <summary>
    /// This option is experimental - it may be replaced with a different mechanism
    /// in the future.
    ///
    /// Configures session thread pools. If this is configured, then RunOptions for
    /// a Run call can select the thread pool to use.
    ///
    /// The intended use is for when some session invocations need to run in a
    /// background pool limited to a small number of threads:
    /// - For example, a session may be configured to have one large pool (for
    /// regular compute) and one small pool (for periodic, low priority work);
    /// using the small pool is currently the mechanism for limiting the inter-op
    /// parallelism of the low priority work.  Note that it does not limit the
    /// parallelism of work spawned by a single op kernel implementation.
    /// - Using this setting is normally not needed in training, but may help some
    /// serving use cases.
    /// - It is also generally recommended to set the global_name field of this
    /// proto, to avoid creating multiple large pools. It is typically better to
    /// run the non-low-priority work, even across sessions, in a single large
    /// pool.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Tensorflow.ThreadPoolOptionProto> SessionInterOpThreadPool {
      get { return sessionInterOpThreadPool_; }
    }

    /// <summary>Field number for the "placement_period" field.</summary>
    public const int PlacementPeriodFieldNumber = 3;
    private int placementPeriod_;
    /// <summary>
    /// Assignment of Nodes to Devices is recomputed every placement_period
    /// steps until the system warms up (at which point the recomputation
    /// typically slows down automatically).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int PlacementPeriod {
      get { return placementPeriod_; }
      set {
        placementPeriod_ = value;
      }
    }

    /// <summary>Field number for the "device_filters" field.</summary>
    public const int DeviceFiltersFieldNumber = 4;
    private static readonly pb::FieldCodec<string> _repeated_deviceFilters_codec
        = pb::FieldCodec.ForString(34);
    private readonly pbc::RepeatedField<string> deviceFilters_ = new pbc::RepeatedField<string>();
    /// <summary>
    /// When any filters are present sessions will ignore all devices which do not
    /// match the filters. Each filter can be partially specified, e.g. "/job:ps"
    /// "/job:worker/replica:3", etc.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> DeviceFilters {
      get { return deviceFilters_; }
    }

    /// <summary>Field number for the "gpu_options" field.</summary>
    public const int GpuOptionsFieldNumber = 6;
    private global::Tensorflow.GPUOptions gpuOptions_;
    /// <summary>
    /// Options that apply to all GPUs.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Tensorflow.GPUOptions GpuOptions {
      get { return gpuOptions_; }
      set {
        gpuOptions_ = value;
      }
    }

    /// <summary>Field number for the "allow_soft_placement" field.</summary>
    public const int AllowSoftPlacementFieldNumber = 7;
    private bool allowSoftPlacement_;
    /// <summary>
    /// Whether soft placement is allowed. If allow_soft_placement is true,
    /// an op will be placed on CPU if
    ///   1. there's no GPU implementation for the OP
    /// or
    ///   2. no GPU devices are known or registered
    /// or
    ///   3. need to co-locate with reftype input(s) which are from CPU.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool AllowSoftPlacement {
      get { return allowSoftPlacement_; }
      set {
        allowSoftPlacement_ = value;
      }
    }

    /// <summary>Field number for the "log_device_placement" field.</summary>
    public const int LogDevicePlacementFieldNumber = 8;
    private bool logDevicePlacement_;
    /// <summary>
    /// Whether device placements should be logged.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool LogDevicePlacement {
      get { return logDevicePlacement_; }
      set {
        logDevicePlacement_ = value;
      }
    }

    /// <summary>Field number for the "graph_options" field.</summary>
    public const int GraphOptionsFieldNumber = 10;
    private global::Tensorflow.GraphOptions graphOptions_;
    /// <summary>
    /// Options that apply to all graphs.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Tensorflow.GraphOptions GraphOptions {
      get { return graphOptions_; }
      set {
        graphOptions_ = value;
      }
    }

    /// <summary>Field number for the "operation_timeout_in_ms" field.</summary>
    public const int OperationTimeoutInMsFieldNumber = 11;
    private long operationTimeoutInMs_;
    /// <summary>
    /// Global timeout for all blocking operations in this session.  If non-zero,
    /// and not overridden on a per-operation basis, this value will be used as the
    /// deadline for all blocking operations.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public long OperationTimeoutInMs {
      get { return operationTimeoutInMs_; }
      set {
        operationTimeoutInMs_ = value;
      }
    }

    /// <summary>Field number for the "rpc_options" field.</summary>
    public const int RpcOptionsFieldNumber = 13;
    private global::Tensorflow.RPCOptions rpcOptions_;
    /// <summary>
    /// Options that apply when this session uses the distributed runtime.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Tensorflow.RPCOptions RpcOptions {
      get { return rpcOptions_; }
      set {
        rpcOptions_ = value;
      }
    }

    /// <summary>Field number for the "cluster_def" field.</summary>
    public const int ClusterDefFieldNumber = 14;
    private global::Tensorflow.ClusterDef clusterDef_;
    /// <summary>
    /// Optional list of all workers to use in this session.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Tensorflow.ClusterDef ClusterDef {
      get { return clusterDef_; }
      set {
        clusterDef_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as ConfigProto);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(ConfigProto other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!DeviceCount.Equals(other.DeviceCount)) return false;
      if (IntraOpParallelismThreads != other.IntraOpParallelismThreads) return false;
      if (InterOpParallelismThreads != other.InterOpParallelismThreads) return false;
      if (UsePerSessionThreads != other.UsePerSessionThreads) return false;
      if(!sessionInterOpThreadPool_.Equals(other.sessionInterOpThreadPool_)) return false;
      if (PlacementPeriod != other.PlacementPeriod) return false;
      if(!deviceFilters_.Equals(other.deviceFilters_)) return false;
      if (!object.Equals(GpuOptions, other.GpuOptions)) return false;
      if (AllowSoftPlacement != other.AllowSoftPlacement) return false;
      if (LogDevicePlacement != other.LogDevicePlacement) return false;
      if (!object.Equals(GraphOptions, other.GraphOptions)) return false;
      if (OperationTimeoutInMs != other.OperationTimeoutInMs) return false;
      if (!object.Equals(RpcOptions, other.RpcOptions)) return false;
      if (!object.Equals(ClusterDef, other.ClusterDef)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= DeviceCount.GetHashCode();
      if (IntraOpParallelismThreads != 0) hash ^= IntraOpParallelismThreads.GetHashCode();
      if (InterOpParallelismThreads != 0) hash ^= InterOpParallelismThreads.GetHashCode();
      if (UsePerSessionThreads != false) hash ^= UsePerSessionThreads.GetHashCode();
      hash ^= sessionInterOpThreadPool_.GetHashCode();
      if (PlacementPeriod != 0) hash ^= PlacementPeriod.GetHashCode();
      hash ^= deviceFilters_.GetHashCode();
      if (gpuOptions_ != null) hash ^= GpuOptions.GetHashCode();
      if (AllowSoftPlacement != false) hash ^= AllowSoftPlacement.GetHashCode();
      if (LogDevicePlacement != false) hash ^= LogDevicePlacement.GetHashCode();
      if (graphOptions_ != null) hash ^= GraphOptions.GetHashCode();
      if (OperationTimeoutInMs != 0L) hash ^= OperationTimeoutInMs.GetHashCode();
      if (rpcOptions_ != null) hash ^= RpcOptions.GetHashCode();
      if (clusterDef_ != null) hash ^= ClusterDef.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      deviceCount_.WriteTo(output, _map_deviceCount_codec);
      if (IntraOpParallelismThreads != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(IntraOpParallelismThreads);
      }
      if (PlacementPeriod != 0) {
        output.WriteRawTag(24);
        output.WriteInt32(PlacementPeriod);
      }
      deviceFilters_.WriteTo(output, _repeated_deviceFilters_codec);
      if (InterOpParallelismThreads != 0) {
        output.WriteRawTag(40);
        output.WriteInt32(InterOpParallelismThreads);
      }
      if (gpuOptions_ != null) {
        output.WriteRawTag(50);
        output.WriteMessage(GpuOptions);
      }
      if (AllowSoftPlacement != false) {
        output.WriteRawTag(56);
        output.WriteBool(AllowSoftPlacement);
      }
      if (LogDevicePlacement != false) {
        output.WriteRawTag(64);
        output.WriteBool(LogDevicePlacement);
      }
      if (UsePerSessionThreads != false) {
        output.WriteRawTag(72);
        output.WriteBool(UsePerSessionThreads);
      }
      if (graphOptions_ != null) {
        output.WriteRawTag(82);
        output.WriteMessage(GraphOptions);
      }
      if (OperationTimeoutInMs != 0L) {
        output.WriteRawTag(88);
        output.WriteInt64(OperationTimeoutInMs);
      }
      sessionInterOpThreadPool_.WriteTo(output, _repeated_sessionInterOpThreadPool_codec);
      if (rpcOptions_ != null) {
        output.WriteRawTag(106);
        output.WriteMessage(RpcOptions);
      }
      if (clusterDef_ != null) {
        output.WriteRawTag(114);
        output.WriteMessage(ClusterDef);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += deviceCount_.CalculateSize(_map_deviceCount_codec);
      if (IntraOpParallelismThreads != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(IntraOpParallelismThreads);
      }
      if (InterOpParallelismThreads != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(InterOpParallelismThreads);
      }
      if (UsePerSessionThreads != false) {
        size += 1 + 1;
      }
      size += sessionInterOpThreadPool_.CalculateSize(_repeated_sessionInterOpThreadPool_codec);
      if (PlacementPeriod != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(PlacementPeriod);
      }
      size += deviceFilters_.CalculateSize(_repeated_deviceFilters_codec);
      if (gpuOptions_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(GpuOptions);
      }
      if (AllowSoftPlacement != false) {
        size += 1 + 1;
      }
      if (LogDevicePlacement != false) {
        size += 1 + 1;
      }
      if (graphOptions_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(GraphOptions);
      }
      if (OperationTimeoutInMs != 0L) {
        size += 1 + pb::CodedOutputStream.ComputeInt64Size(OperationTimeoutInMs);
      }
      if (rpcOptions_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(RpcOptions);
      }
      if (clusterDef_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(ClusterDef);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(ConfigProto other) {
      if (other == null) {
        return;
      }
      deviceCount_.Add(other.deviceCount_);
      if (other.IntraOpParallelismThreads != 0) {
        IntraOpParallelismThreads = other.IntraOpParallelismThreads;
      }
      if (other.InterOpParallelismThreads != 0) {
        InterOpParallelismThreads = other.InterOpParallelismThreads;
      }
      if (other.UsePerSessionThreads != false) {
        UsePerSessionThreads = other.UsePerSessionThreads;
      }
      sessionInterOpThreadPool_.Add(other.sessionInterOpThreadPool_);
      if (other.PlacementPeriod != 0) {
        PlacementPeriod = other.PlacementPeriod;
      }
      deviceFilters_.Add(other.deviceFilters_);
      if (other.gpuOptions_ != null) {
        if (gpuOptions_ == null) {
          gpuOptions_ = new global::Tensorflow.GPUOptions();
        }
        GpuOptions.MergeFrom(other.GpuOptions);
      }
      if (other.AllowSoftPlacement != false) {
        AllowSoftPlacement = other.AllowSoftPlacement;
      }
      if (other.LogDevicePlacement != false) {
        LogDevicePlacement = other.LogDevicePlacement;
      }
      if (other.graphOptions_ != null) {
        if (graphOptions_ == null) {
          graphOptions_ = new global::Tensorflow.GraphOptions();
        }
        GraphOptions.MergeFrom(other.GraphOptions);
      }
      if (other.OperationTimeoutInMs != 0L) {
        OperationTimeoutInMs = other.OperationTimeoutInMs;
      }
      if (other.rpcOptions_ != null) {
        if (rpcOptions_ == null) {
          rpcOptions_ = new global::Tensorflow.RPCOptions();
        }
        RpcOptions.MergeFrom(other.RpcOptions);
      }
      if (other.clusterDef_ != null) {
        if (clusterDef_ == null) {
          clusterDef_ = new global::Tensorflow.ClusterDef();
        }
        ClusterDef.MergeFrom(other.ClusterDef);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            deviceCount_.AddEntriesFrom(input, _map_deviceCount_codec);
            break;
          }
          case 16: {
            IntraOpParallelismThreads = input.ReadInt32();
            break;
          }
          case 24: {
            PlacementPeriod = input.ReadInt32();
            break;
          }
          case 34: {
            deviceFilters_.AddEntriesFrom(input, _repeated_deviceFilters_codec);
            break;
          }
          case 40: {
            InterOpParallelismThreads = input.ReadInt32();
            break;
          }
          case 50: {
            if (gpuOptions_ == null) {
              gpuOptions_ = new global::Tensorflow.GPUOptions();
            }
            input.ReadMessage(gpuOptions_);
            break;
          }
          case 56: {
            AllowSoftPlacement = input.ReadBool();
            break;
          }
          case 64: {
            LogDevicePlacement = input.ReadBool();
            break;
          }
          case 72: {
            UsePerSessionThreads = input.ReadBool();
            break;
          }
          case 82: {
            if (graphOptions_ == null) {
              graphOptions_ = new global::Tensorflow.GraphOptions();
            }
            input.ReadMessage(graphOptions_);
            break;
          }
          case 88: {
            OperationTimeoutInMs = input.ReadInt64();
            break;
          }
          case 98: {
            sessionInterOpThreadPool_.AddEntriesFrom(input, _repeated_sessionInterOpThreadPool_codec);
            break;
          }
          case 106: {
            if (rpcOptions_ == null) {
              rpcOptions_ = new global::Tensorflow.RPCOptions();
            }
            input.ReadMessage(rpcOptions_);
            break;
          }
          case 114: {
            if (clusterDef_ == null) {
              clusterDef_ = new global::Tensorflow.ClusterDef();
            }
            input.ReadMessage(clusterDef_);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// Options for a single Run() call.
  /// </summary>
  public sealed partial class RunOptions : pb::IMessage<RunOptions> {
    private static readonly pb::MessageParser<RunOptions> _parser = new pb::MessageParser<RunOptions>(() => new RunOptions());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<RunOptions> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Tensorflow.ConfigReflection.Descriptor.MessageTypes[6]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RunOptions() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RunOptions(RunOptions other) : this() {
      traceLevel_ = other.traceLevel_;
      timeoutInMs_ = other.timeoutInMs_;
      interOpThreadPool_ = other.interOpThreadPool_;
      outputPartitionGraphs_ = other.outputPartitionGraphs_;
      DebugOptions = other.debugOptions_ != null ? other.DebugOptions.Clone() : null;
      reportTensorAllocationsUponOom_ = other.reportTensorAllocationsUponOom_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RunOptions Clone() {
      return new RunOptions(this);
    }

    /// <summary>Field number for the "trace_level" field.</summary>
    public const int TraceLevelFieldNumber = 1;
    private global::Tensorflow.RunOptions.Types.TraceLevel traceLevel_ = 0;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Tensorflow.RunOptions.Types.TraceLevel TraceLevel {
      get { return traceLevel_; }
      set {
        traceLevel_ = value;
      }
    }

    /// <summary>Field number for the "timeout_in_ms" field.</summary>
    public const int TimeoutInMsFieldNumber = 2;
    private long timeoutInMs_;
    /// <summary>
    /// Time to wait for operation to complete in milliseconds.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public long TimeoutInMs {
      get { return timeoutInMs_; }
      set {
        timeoutInMs_ = value;
      }
    }

    /// <summary>Field number for the "inter_op_thread_pool" field.</summary>
    public const int InterOpThreadPoolFieldNumber = 3;
    private int interOpThreadPool_;
    /// <summary>
    /// The thread pool to use, if session_inter_op_thread_pool is configured.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int InterOpThreadPool {
      get { return interOpThreadPool_; }
      set {
        interOpThreadPool_ = value;
      }
    }

    /// <summary>Field number for the "output_partition_graphs" field.</summary>
    public const int OutputPartitionGraphsFieldNumber = 5;
    private bool outputPartitionGraphs_;
    /// <summary>
    /// Whether the partition graph(s) executed by the executor(s) should be
    /// outputted via RunMetadata.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool OutputPartitionGraphs {
      get { return outputPartitionGraphs_; }
      set {
        outputPartitionGraphs_ = value;
      }
    }

    /// <summary>Field number for the "debug_options" field.</summary>
    public const int DebugOptionsFieldNumber = 6;
    private global::Tensorflow.DebugOptions debugOptions_;
    /// <summary>
    /// EXPERIMENTAL.  Options used to initialize DebuggerState, if enabled.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Tensorflow.DebugOptions DebugOptions {
      get { return debugOptions_; }
      set {
        debugOptions_ = value;
      }
    }

    /// <summary>Field number for the "report_tensor_allocations_upon_oom" field.</summary>
    public const int ReportTensorAllocationsUponOomFieldNumber = 7;
    private bool reportTensorAllocationsUponOom_;
    /// <summary>
    /// When enabled, causes tensor alllocation information to be included in
    /// the error message when the Run() call fails because the allocator ran
    /// out of memory (OOM).
    ///
    /// Enabling this option can slow down the Run() call.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool ReportTensorAllocationsUponOom {
      get { return reportTensorAllocationsUponOom_; }
      set {
        reportTensorAllocationsUponOom_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as RunOptions);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(RunOptions other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (TraceLevel != other.TraceLevel) return false;
      if (TimeoutInMs != other.TimeoutInMs) return false;
      if (InterOpThreadPool != other.InterOpThreadPool) return false;
      if (OutputPartitionGraphs != other.OutputPartitionGraphs) return false;
      if (!object.Equals(DebugOptions, other.DebugOptions)) return false;
      if (ReportTensorAllocationsUponOom != other.ReportTensorAllocationsUponOom) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (TraceLevel != 0) hash ^= TraceLevel.GetHashCode();
      if (TimeoutInMs != 0L) hash ^= TimeoutInMs.GetHashCode();
      if (InterOpThreadPool != 0) hash ^= InterOpThreadPool.GetHashCode();
      if (OutputPartitionGraphs != false) hash ^= OutputPartitionGraphs.GetHashCode();
      if (debugOptions_ != null) hash ^= DebugOptions.GetHashCode();
      if (ReportTensorAllocationsUponOom != false) hash ^= ReportTensorAllocationsUponOom.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (TraceLevel != 0) {
        output.WriteRawTag(8);
        output.WriteEnum((int) TraceLevel);
      }
      if (TimeoutInMs != 0L) {
        output.WriteRawTag(16);
        output.WriteInt64(TimeoutInMs);
      }
      if (InterOpThreadPool != 0) {
        output.WriteRawTag(24);
        output.WriteInt32(InterOpThreadPool);
      }
      if (OutputPartitionGraphs != false) {
        output.WriteRawTag(40);
        output.WriteBool(OutputPartitionGraphs);
      }
      if (debugOptions_ != null) {
        output.WriteRawTag(50);
        output.WriteMessage(DebugOptions);
      }
      if (ReportTensorAllocationsUponOom != false) {
        output.WriteRawTag(56);
        output.WriteBool(ReportTensorAllocationsUponOom);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (TraceLevel != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) TraceLevel);
      }
      if (TimeoutInMs != 0L) {
        size += 1 + pb::CodedOutputStream.ComputeInt64Size(TimeoutInMs);
      }
      if (InterOpThreadPool != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(InterOpThreadPool);
      }
      if (OutputPartitionGraphs != false) {
        size += 1 + 1;
      }
      if (debugOptions_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(DebugOptions);
      }
      if (ReportTensorAllocationsUponOom != false) {
        size += 1 + 1;
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(RunOptions other) {
      if (other == null) {
        return;
      }
      if (other.TraceLevel != 0) {
        TraceLevel = other.TraceLevel;
      }
      if (other.TimeoutInMs != 0L) {
        TimeoutInMs = other.TimeoutInMs;
      }
      if (other.InterOpThreadPool != 0) {
        InterOpThreadPool = other.InterOpThreadPool;
      }
      if (other.OutputPartitionGraphs != false) {
        OutputPartitionGraphs = other.OutputPartitionGraphs;
      }
      if (other.debugOptions_ != null) {
        if (debugOptions_ == null) {
          debugOptions_ = new global::Tensorflow.DebugOptions();
        }
        DebugOptions.MergeFrom(other.DebugOptions);
      }
      if (other.ReportTensorAllocationsUponOom != false) {
        ReportTensorAllocationsUponOom = other.ReportTensorAllocationsUponOom;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 8: {
            traceLevel_ = (global::Tensorflow.RunOptions.Types.TraceLevel) input.ReadEnum();
            break;
          }
          case 16: {
            TimeoutInMs = input.ReadInt64();
            break;
          }
          case 24: {
            InterOpThreadPool = input.ReadInt32();
            break;
          }
          case 40: {
            OutputPartitionGraphs = input.ReadBool();
            break;
          }
          case 50: {
            if (debugOptions_ == null) {
              debugOptions_ = new global::Tensorflow.DebugOptions();
            }
            input.ReadMessage(debugOptions_);
            break;
          }
          case 56: {
            ReportTensorAllocationsUponOom = input.ReadBool();
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the RunOptions message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      /// TODO(pbar) Turn this into a TraceOptions proto which allows
      /// tracing to be controlled in a more orthogonal manner?
      /// </summary>
      public enum TraceLevel {
        [pbr::OriginalName("NO_TRACE")] NoTrace = 0,
        [pbr::OriginalName("SOFTWARE_TRACE")] SoftwareTrace = 1,
        [pbr::OriginalName("HARDWARE_TRACE")] HardwareTrace = 2,
        [pbr::OriginalName("FULL_TRACE")] FullTrace = 3,
      }

    }
    #endregion

  }

  /// <summary>
  /// Metadata output (i.e., non-Tensor) for a single Run() call.
  /// </summary>
  public sealed partial class RunMetadata : pb::IMessage<RunMetadata> {
    private static readonly pb::MessageParser<RunMetadata> _parser = new pb::MessageParser<RunMetadata>(() => new RunMetadata());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<RunMetadata> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Tensorflow.ConfigReflection.Descriptor.MessageTypes[7]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RunMetadata() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RunMetadata(RunMetadata other) : this() {
      StepStats = other.stepStats_ != null ? other.StepStats.Clone() : null;
      CostGraph = other.costGraph_ != null ? other.CostGraph.Clone() : null;
      partitionGraphs_ = other.partitionGraphs_.Clone();
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RunMetadata Clone() {
      return new RunMetadata(this);
    }

    /// <summary>Field number for the "step_stats" field.</summary>
    public const int StepStatsFieldNumber = 1;
    private global::Tensorflow.StepStats stepStats_;
    /// <summary>
    /// Statistics traced for this step. Populated if tracing is turned on via the
    /// "RunOptions" proto.
    /// EXPERIMENTAL: The format and set of events may change in future versions.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Tensorflow.StepStats StepStats {
      get { return stepStats_; }
      set {
        stepStats_ = value;
      }
    }

    /// <summary>Field number for the "cost_graph" field.</summary>
    public const int CostGraphFieldNumber = 2;
    private global::Tensorflow.CostGraphDef costGraph_;
    /// <summary>
    /// The cost graph for the computation defined by the run call.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Tensorflow.CostGraphDef CostGraph {
      get { return costGraph_; }
      set {
        costGraph_ = value;
      }
    }

    /// <summary>Field number for the "partition_graphs" field.</summary>
    public const int PartitionGraphsFieldNumber = 3;
    private static readonly pb::FieldCodec<global::Tensorflow.GraphDef> _repeated_partitionGraphs_codec
        = pb::FieldCodec.ForMessage(26, global::Tensorflow.GraphDef.Parser);
    private readonly pbc::RepeatedField<global::Tensorflow.GraphDef> partitionGraphs_ = new pbc::RepeatedField<global::Tensorflow.GraphDef>();
    /// <summary>
    /// Graphs of the partitions executed by executors.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Tensorflow.GraphDef> PartitionGraphs {
      get { return partitionGraphs_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as RunMetadata);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(RunMetadata other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(StepStats, other.StepStats)) return false;
      if (!object.Equals(CostGraph, other.CostGraph)) return false;
      if(!partitionGraphs_.Equals(other.partitionGraphs_)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (stepStats_ != null) hash ^= StepStats.GetHashCode();
      if (costGraph_ != null) hash ^= CostGraph.GetHashCode();
      hash ^= partitionGraphs_.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (stepStats_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(StepStats);
      }
      if (costGraph_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(CostGraph);
      }
      partitionGraphs_.WriteTo(output, _repeated_partitionGraphs_codec);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (stepStats_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(StepStats);
      }
      if (costGraph_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(CostGraph);
      }
      size += partitionGraphs_.CalculateSize(_repeated_partitionGraphs_codec);
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(RunMetadata other) {
      if (other == null) {
        return;
      }
      if (other.stepStats_ != null) {
        if (stepStats_ == null) {
          stepStats_ = new global::Tensorflow.StepStats();
        }
        StepStats.MergeFrom(other.StepStats);
      }
      if (other.costGraph_ != null) {
        if (costGraph_ == null) {
          costGraph_ = new global::Tensorflow.CostGraphDef();
        }
        CostGraph.MergeFrom(other.CostGraph);
      }
      partitionGraphs_.Add(other.partitionGraphs_);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            if (stepStats_ == null) {
              stepStats_ = new global::Tensorflow.StepStats();
            }
            input.ReadMessage(stepStats_);
            break;
          }
          case 18: {
            if (costGraph_ == null) {
              costGraph_ = new global::Tensorflow.CostGraphDef();
            }
            input.ReadMessage(costGraph_);
            break;
          }
          case 26: {
            partitionGraphs_.AddEntriesFrom(input, _repeated_partitionGraphs_codec);
            break;
          }
        }
      }
    }

  }

  #endregion

}

#endregion Designer generated code
